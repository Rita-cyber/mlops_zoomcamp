{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6cdb73",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_data_preprocess() missing 7 required positional arguments: 'raw_data_path', 'dest_path', 'year', 'dataset', 'train_month', 'val_month', and 'test_month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     dump_pickle((X_test, y_test), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dest_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mrun_data_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_data_preprocess() missing 7 required positional arguments: 'raw_data_path', 'dest_path', 'year', 'dataset', 'train_month', 'val_month', and 'test_month'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "def dump_pickle(obj, filename: str):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)\n",
    "    \n",
    "def load_raw_data(fileurl:str):\n",
    "    df = pd.read_parquet(fileurl)\n",
    "    return df\n",
    "    \n",
    "def remove_outlier(df: pd.DataFrame):\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "    df['duration_mins']= (df['duration']).dt.total_seconds() / 60\n",
    "    df= df[(df.duration_mins >= 1) & (df.duration_mins <= 60)]\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df\n",
    "    \n",
    "def preprocess_data(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "    \n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--url\",\n",
    "    help=\"weblink where the raw NYC taxi trip data was saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--dest_path\",\n",
    "    help=\"Location where the resulting files will be saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--dest_path\",\n",
    "    help=\"Location where the resulting files will be saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--dest_path\",\n",
    "    help=\"Location where the resulting files will be saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--year\",\n",
    "    help=\"Data year\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--train_month\",\n",
    "    help=\"month of the train data\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--val_month\",\n",
    "    help=\"month of the validation data\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--test_month\",\n",
    "    help=\"month of the test data\"\n",
    ")\n",
    "def run_data_preprocess(url:str,dest_path:str,year: int,train_month: int, val_month: int,test_month: int,dataset: str = \"green\"):\n",
    "    # Load parquet files\n",
    "    df_train_dataset = load_raw_data(f\"{url}/{dataset}_tripdata_{year}-{train_month}.parquet\")\n",
    "    df_validate_dataset = load_raw_data(f\"{url}/{dataset}_tripdata_{year}-{val_month}.parquet\")\n",
    "    df_test_dataset = load_raw_data(f\"{url}/{dataset}_tripdata_{year}-{test_month}.parquet\")\n",
    "    \n",
    "    df_train = remove_outlier(df_train_dataset)\n",
    "    df_validate = remove_outlier(df_validate_dataset)\n",
    "    df_test = remove_outlier(df_test_dataset)\n",
    "    \n",
    "    # Extract the target\n",
    "    target = 'duration_mins'\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_validate[target].values\n",
    "    y_test = df_test[target].values\n",
    "                            \n",
    "    # Fit the DictVectorizer and preprocess data\n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess_data(df_train, dv, fit_dv=True)\n",
    "    X_val, _ = preprocess_data(df_validate, dv, fit_dv=False)\n",
    "    X_test, _ = preprocess_data(df_test, dv, fit_dv=False)\n",
    "    \n",
    "    # Create dest_path folder unless it already exists\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    # Save DictVectorizer and datasets\n",
    "    dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
    "    dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
    "    dump_pickle((X_val, y_val), os.path.join(dest_path, \"val.pkl\"))\n",
    "    dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_data_preprocess()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397ca99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
