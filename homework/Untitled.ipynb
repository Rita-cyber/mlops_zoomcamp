{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6cdb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(filename:str):\n",
    "    df = pd.read_parquet(filename)\n",
    "    return df\n",
    "    \n",
    "def outlier():\n",
    "    df['duration'] = df.tpep_dropoff_datetime-df.tpep_pickup_datetime\n",
    "    df['duration_mins']= (df['duration']).dt.total_seconds() / 60\n",
    "    df_outlier= df[(df.duration_mins >= 1) & (df.duration_mins <= 60)]\n",
    "    return df_outlier\n",
    "    \n",
    "def preprocess_data(column1:str,column2:str,dv: DictVectorizer,fit_dv: bool = False)\n",
    "    # 1. Turn your dataframe into a list of dictionaries\n",
    "    df_outlier_dicts = df_outlier[[column1, column2]].astype(str).to_dict(orient='records')\n",
    "\n",
    "# 2. Initialize the DictVectorizer\n",
    "\n",
    "# 3. Fit and transform the data\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "    \n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--raw_data_path\",\n",
    "    help=\"Location where the raw NYC taxi trip data was saved\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--dest_path\",\n",
    "    help=\"Location where the resulting files will be saved\"\n",
    ")\n",
    "\n",
    "def run_data_preprocess(raw_data_path:str,dest_path:str,year: int,dataset:str, train_month: int, val_month: int,test_month):\n",
    "    # Load parquet files\n",
    "    df_train = load_raw_data(os.path.join(raw_data_path, f\"{dataset}_tripdata_{year}-{train_month}.parquet\")\n",
    "    df_validate = load_raw_data(os.path.join(raw_data_path, f\"{dataset}_tripdata_{year}-{val_month}.parquet\")\n",
    "    df_test = load_raw_data(os.path.join(raw_data_path, f\"{dataset}_tripdata_{year}-{test_month}.parquet\")\n",
    "    \n",
    "    # Extract the target\n",
    "    target = 'duration'\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "    y_test = df_test[target].values\n",
    "                            \n",
    "    # Fit the DictVectorizer and preprocess data\n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
    "    X_val, _ = preprocess(df_val, dv, fit_dv=False)\n",
    "    X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10de53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in /home/codespace/anaconda3/lib/python3.9/site-packages (8.0.4)\r\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734fdec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
